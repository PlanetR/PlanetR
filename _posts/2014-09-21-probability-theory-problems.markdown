---
title: "Probability Theory Problems"
kind: article
created_at: 2014-09-21 03:56:00 UTC
author: Alstatr
categories: 
tags: 
layout: post
---
<div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on">Let's have fun on probability theory, here is my first problem set in the said subject.<br /><br /><h3>Problems</h3><ol><li>It was noted that statisticians who follow the deFinetti school do not accept the Axiom of Countable Additivity, instead adhering to the Axiom of Finite Additivity. <ol type="a"><li>Show that the Axiom of Countable Additivity implies Finite Additivity.</li><li>Although, by itself, the Axiom of Finite Additivity does not imply Countable Additivity, suppose we supplement it with the following. Let $A_1\supset A_2\supset\cdots\supset A_n\supset \cdots$ be an infinite sequence of nested sets whose limit is the empty set, which we denote by $A_n\downarrow\emptyset$. Consider the following:<br /><br /><div style="text-align: center;"><b>Axiom of Continuity:</b> If $A_n\downarrow\emptyset$, then $P(A_n)\rightarrow 0$ </div><br />Prove that the Axiom of Continuity and the Axiom of Finite Additivity imply Countable Additivity. </li></ol></li><li>Prove each of the following statements. (Assume that any conditioning event has positive probability.) <ol type="a"><li> If $P(B)=1$, then $P(A|B)=P(A)$ for any $A$.</li><li> If $A\subset B$, then $P(B|A)=1$ and $P(A|B)=P(A)/P(B)$.</li><li> If $A$ and $B$ are mutually exclusive, then \begin{equation}\nonumber P(A|A\cup B) = \displaystyle\frac{P(A)}{P(A)+P(B)}. \end{equation}</li><li> $P(A\cap B\cap C)=P(A|B\cap C)P(B|C)P(C)$.</li></ol></li><a name='more'></a><li>Prove that the following functions are cdfs. <ol type="a"><li> $\frac{1}{2}+\frac{1}{\pi}\arctan(x), x\in (-\infty, \infty)$</li><li> $(1+e^{-x})^{-1},x\in (-\infty,\infty)$</li><li> $e^{-e^{-x}}, x\in (-\infty, \infty)$</li><li> $1-e^{-x}, x\in (0,\infty)$</li><li> the function defined in (1.5.6), (Check in the reference below.)</li></ol></li><li>A cdf $F_X$ is <i>stochastically</i> greater than a cdf $F_{Y}$ if $F_{X}(t)\leq F_{Y}(t)$ for all $t$ and $F_{X}(t) &lt; F_{Y}(t)$ for some $t$. Prove that if $X\sim F_X$ and $Y\sim F_Y$, then \begin{equation}\nonumber P(X&gt;t) \geq P(Y&gt;t)\;\text{for every}\;t \end{equation} and  \begin{equation}\nonumber P(X&gt;t)&gt;P(Y&gt;t),\;\text{for some}\; t \end{equation} that is, $X$ tends to be bigger than $Y$.</li><li> Let $X$ be a continuous random variable with pdf $f(x)$ and cdf $F(x)$. For a fixed number $x_0$, define the function \begin{equation}\nonumber g(x) = \begin{cases} f(x) / [1-F(x_0)]&amp; x \geq x_0\\ 0 &amp; x &lt; x_0. \end{cases} \end{equation} Prove that $g(x)$ is a pdf. (Assume that $F(x_0)<1$.)</li><li>For each of the following, determine the value of $c$ that makes $f(x)$ a pdf. <ol type="a"><li> $f(x)=\mathrm{c}\sin x, 0 &lt; x &lt; \pi/2$</li><li> $f(x)=\mathrm{c}e^{-|x|},-\infty &lt; x &lt; \infty$</li></ol></li></ol><br /><h3>Solutions</h3><ol><li><ol type="a"><li><i>Proof</i>. Let $\mathscr{B}$ be a $\sigma$-algebra and consider $A_1,A_2,\cdots\in \mathscr{B}$ are pairwise disjoint, then by countable additivity \begin{equation}\nonumber P\left(\displaystyle\bigcup_{i=1}^{\infty}A_i\right)=\displaystyle\sum_{i=1}^{\infty}P(A_i). \end{equation} Now,  \begin{equation} \begin{aligned} P\left(\displaystyle\bigcup_{i=1}^{\infty}A_i\right)&amp;= P\left(\displaystyle\bigcup_{i=1}^{n}A_i\cup\displaystyle \bigcup_{i=n+1}^{\infty}A_i\right)\\ &amp;= P\left(\displaystyle\bigcup_{i=1}^{n}A_i\right)+P\left(\displaystyle \bigcup_{i=n+1}^{\infty}A_i\right),\;(\text{since}\;A_i's\;\text{are disjoints})\\ &amp;=P(A_1)+\cdots+P(A_n)+P\left(\displaystyle \bigcup_{i=n+1}^{\infty}A_i\right),\\ &amp;\quad(\text{by finite additivity})\\ &amp;=\displaystyle\sum_{i=1}^{n}P(A_i)+P\left(\displaystyle \bigcup_{i=n+1}^{\infty}A_i\right) \end{aligned}\nonumber \end{equation} Notice that for any $n$, we can consider $P(A_i),\;i&gt;n$ to be empty. Implying  \begin{equation}\nonumber P\left(\displaystyle\bigcup_{i=n+1}^{\infty}A_i\right)=\displaystyle \sum_{i=n+1}^{\infty}P(A_i)=P(\emptyset)+P(\emptyset)+\cdots, \end{equation} that is, \begin{equation}\nonumber \begin{aligned} P\left(\displaystyle\bigcup_{i=1}^{\infty}A_i\right)&amp;= \displaystyle\sum_{i=1}^{n}P(A_i)+\sum_{i=n+1}^{\infty}P(A_i)\\ &amp;=\displaystyle\sum_{i=1}^{n}P(A_i)+P(\emptyset)+P(\emptyset)+\cdots \end{aligned} \end{equation} $\therefore$ countable additivity implies finite additivity. <br />$\hspace{12.5cm}\blacksquare$ </li><li>From (a), we have shown that countable additivity implies finite additivity, i.e., \begin{equation} P\left(\displaystyle\bigcup_{i=1}^{\infty}A_i\right)=\displaystyle\sum_{i=1}^{n}P(A_i)+P\left(\displaystyle \bigcup_{i=n+1}^{\infty}A_i\right) \nonumber \end{equation} If we supplement this with the following condition, that $A_1\supset A_2\supset A_3\supset\cdots$. By Axiom of Continuity, $\displaystyle\lim_{n\to \infty}A_n=\emptyset$, and by <a href="http://alstatr.blogspot.com/2014/09/monotonic-sequential-continuity.html" target="_blank">Monotone Sequential Continuity</a>, $P\left(\displaystyle\lim_{n\to\infty}A_n\right)= \displaystyle\lim_{n\to\infty}P(A_n)=0$. Now we can write $A_1\supset A_2\supset A_3\supset\cdots$ as \begin{equation}\nonumber B_k=\bigcup_{i=k}^{\infty}A_i,\;\text{such that}\;B_{k+1}\subset B_k, \text{implying}\; \lim_{k\to\infty}B_k=\emptyset \end{equation} Thus, finite additivity plus axiom of continuity, we have \begin{equation}\nonumber \begin{aligned} P\left(\bigcup_{i=1}^{\infty}A_i\right)&amp;=\lim_{n\to\infty}\left( \sum_{i=1}^{n}P(A_i)+P(B_{n+1})\right)\\ &amp;=\lim_{n\to\infty}\left(\sum_{i=1}^{n}P(A_i)\right)+\lim_{n\to\infty} P(B_{n+1})\\ &amp;=\sum_{i=1}^{\infty}P(A_i)+0,\;(\text{by axiom of continuity}). \end{aligned} \end{equation} Implying countable additivity.<br />$\hspace{12.5cm}\blacksquare$</li></ol></li><li><ol type="a"><li><i>Proof</i>. If $P(B)=1$, then $P(S)=P(B)=1$. Because $A\subseteq S$, implies $A\subseteq B$. Thus, $A\cap B = A$, and therefore \begin{equation}\nonumber P(A|B)=\displaystyle\frac{P(A\cap B)}{P(B)}=\displaystyle\frac{P(A)}{P(B)}=P(A) \end{equation} $\hspace{12.5cm}\blacksquare$ </li><li><i>Proof</i>. If $A\subseteq B$ then \begin{equation}\nonumber P(B|A)=\displaystyle\frac{P(A\cap B)}{P(A)}=\displaystyle\frac{P(A)}{P(A)}=1 \end{equation} and, \begin{equation}\nonumber P(A|B)=\displaystyle\frac{P(A\cap B)}{P(B)}=\displaystyle\frac{P(A)}{P(B)} \end{equation} $\hspace{12.5cm}\blacksquare$ </li><li><i>Proof</i>. If $A$ and $B$ are mutually exclusive, then \begin{equation} \nonumber \begin{aligned} P(A|A\cup B)&amp;=\displaystyle\frac{P(A\cap (A\cup B))}{P(A\cup B)}\\ &amp;=\displaystyle\frac{P(A)\cup [P(A\cap B)]}{P(A)+ P(B)}\\ &amp;=\displaystyle\frac{P(A)}{P(A)+ P(B)} \end{aligned} \end{equation}$\hspace{12.5cm}\blacksquare$</li><li><i>Proof</i>. Consider, \begin{equation}\nonumber P(A|B\cap C)=\displaystyle\frac{P(A\cap B\cap C)}{P(B\cap C)} \end{equation} Hence, \begin{equation}\nonumber P(A\cap B\cap C) = P(A|B\cap C)P(B\cap C) \end{equation} Now $P(B\cap C)=P(B|C)P(C)$, therefore \begin{equation}\nonumber P(A\cap B\cap C) = P(A|B\cap C)P(B|C)P(C) \end{equation}$\hspace{12.5cm}\blacksquare$</li></ol></li><li>$F(x)$ is a cdf if it satisfies the following conditions: <ol type="i"><li>$\displaystyle\lim_{x\to-\infty}F(x)=0$ and $\displaystyle\lim_{x\to\infty}F(x)=1$</li><li>$F(x)$ is nondecreasing.</li><li>$F(x)$ is right-continuous.</li></ol><ol type="a"><li><i>Proof</i>. <ol type="i"><li> $F(x)=\frac{1}{2}+\frac{1}{\pi}\arctan(x), x\in (-\infty, \infty)$ <div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"><img border="0" src="http://3.bp.blogspot.com/-Nn76h1_Ktbo/VB19Pgc_HaI/AAAAAAAAB88/m1Siu84edNU/s1600/Screenshot%2Bfrom%2B2014-09-20%2B21%3A11%3A29.png" /></div>Above figure was generated by the following $\mathrm{\LaTeX}$ codes:<br/><br/><script src="https://gist.github.com/alstat/79dee5ee372d810e0e1b.js"></script>\begin{equation}\nonumber \begin{aligned} \displaystyle\lim_{x\to-\infty}F(x)&amp;=\displaystyle\lim_{x\to-\infty} \left(\frac{1}{2}+\frac{1}{\pi}\arctan(x)\right)\\ &amp;=\frac{1}{2}+\frac{1}{\pi}\displaystyle\lim_{x\to-\infty}\left(\arctan(x)\right)\\ &amp;=\frac{1}{2}+\frac{1}{\pi} \left(\frac{-\pi}{2}\right),\;\text{since}\;\displaystyle\lim_{x\to-\frac{\pi}{2}}\frac{\sin(x)}{\cos(x)}=-\infty\\ &amp;=0\\[0.5cm] \displaystyle\lim_{x\to\infty}F(x)&amp;=\displaystyle\lim_{x\to\infty} \left(\frac{1}{2}+\frac{1}{\pi}\arctan(x)\right)\\ &amp;=\frac{1}{2}+\frac{1}{\pi}\displaystyle\lim_{x\to\infty}\left(\arctan(x)\right)\\ &amp;=\frac{1}{2}+\frac{1}{\pi} \left(\frac{\pi}{2}\right),\;\text{since}\;\displaystyle\lim_{x\to\frac{\pi}{2}}\frac{\sin(x)}{\cos(x)}=\infty\\ &amp;=1 \end{aligned} \end{equation}</li><li> To test if $F(x)$ is nondecreasing, recall in Calculus that, first differentiation of the function tells us if it is decreasing or increasing. In particular, $\frac{dF(x)}{dx}&gt;0$ tells us that the function is increasing in a given interval of $x$. Thus, \begin{equation} \nonumber \frac{dF(x)}{dx}=\frac{d}{dx}\left(\frac{1}{2}+\frac{1}{\pi}\arctan(x)\right)=\frac{1}{\pi(1+x^2)} \end{equation} Confirm the above differentiation with Python using <a href="http://sympy.org/" target = "_blank">sympy</a> module. <br/><br/><script src="https://gist.github.com/alstat/f58b1a6f567cd7b1f302.js"></script>Since $x^2$ is always positive for all $x$, thus $\frac{dF(x)}{dx}&gt;0$, implying $F(x)$ is increasing.</li><li> $F(x)$ is continuous, implies that $F(x)$ is right-continuous.</li></ol>$\hspace{12.5cm}\blacksquare$ </li><li><i>Proof</i>. <ol type="i"><li>$ F(x)=\displaystyle\frac{1}{1+e^{-x}}, x\in(-\infty,\infty) $ <div class="separator" style="clear: both; text-align: center;"><img border="0" src="http://3.bp.blogspot.com/-06G5SEwr-5M/VB19gNTYPZI/AAAAAAAAB9E/ot8Mwk7EnoM/s1600/Screenshot%2Bfrom%2B2014-09-20%2B21%3A13%3A04.png" /></div>\begin{equation}\nonumber \begin{aligned} \displaystyle\lim_{x\to-\infty}F(x)&amp;=\displaystyle\lim_{x\to-\infty} \left(\frac{1}{1+e^{-x}}\right)\\ &amp;=0\\[0.5cm] \displaystyle\lim_{x\to\infty}F(x)&amp;=\displaystyle\lim_{x\to\infty} \left(\frac{1}{1+e^{-x}}\right)\\ &amp;=\displaystyle\lim_{x\to\infty} \left(\frac{1}{1+\frac{1}{e^{x}}}\right)\\ &amp;=1 \end{aligned} \end{equation} Confirm these in Python,<br/><br/><script src="https://gist.github.com/alstat/cc73f0976d9827f4ff0c.js"></script></li><li> Using the same method we did in (a), we have \begin{equation} \nonumber \begin{aligned} \frac{dF(x)}{dx}&amp;=\frac{d}{dx}\left(\displaystyle\frac{1}{1+e^{-x}}\right)\\ &amp;=\frac{e^{-x}}{(1+e^{-x})^2} \end{aligned} \end{equation} $\frac{dF(x)}{dx}=\frac{e^{-x}}{(1+e^{-x})^2}&gt;0,\;\forall\;x\in(-\infty,\infty)$. Thus the function is increasing in the interval of $x$.</li><li> $F(x)$ is continuous, implies the function is right-continuous. </li></ol>$\hspace{12.5cm}\blacksquare$ </li><li><i>Proof</i>.  <ol type="i"><li>$F(x)=e^{-e^{-x}}, x\in (-\infty, \infty)$ <div class="separator" style="clear: both; text-align: center;"><img border="0" src="http://1.bp.blogspot.com/-EpbuWCoCeoI/VB1-joagOzI/AAAAAAAAB9M/iJMwXvk2P1c/s1600/Screenshot%2Bfrom%2B2014-09-20%2B21%3A16%3A51.png" /></div>\begin{equation}\nonumber \begin{aligned} \displaystyle\lim_{x\to-\infty}F(x)&amp;=\displaystyle\lim_{x\to-\infty} \left(e^{-e^{-x}}\right)\\ &amp;=\displaystyle\lim_{x\to-\infty} \left(\frac{1}{e^{\frac{1}{e^{x}}}}\right)\\ &amp;=0\\[0.5cm] \displaystyle\lim_{x\to\infty}F(x)&amp;=\displaystyle\lim_{x\to\infty} \left(e^{-e^{-x}}\right)\\ &amp;=\displaystyle\lim_{x\to\infty} \left(\frac{1}{e^{\frac{1}{e^{x}}}}\right)\\ &amp;=1 \end{aligned} \end{equation}</li><li>Like what we did above, $\frac{dF(x)}{dx}$ is, \begin{equation} \nonumber \frac{dF(x)}{dx}=\frac{d}{dx}\left(e^{-e^{-x}}\right)=e^{-x}e^{-e^{-x}}&gt;0 \end{equation} Because $e^{-x}e^{-e^{-x}}&gt;0,\;\forall\; x\in(-\infty,\infty)$. Then we say $F(x)$ is an increasing function in the interval of $x$.</li><li>$F(x)$ is continuous, implies that $F(x)$ is right-continuous.</li></ol>$\hspace{12.5cm}\blacksquare$ </li><li><i>Proof</i>. <ol type="i"><li>$F(x)=1-\displaystyle\frac{1}{e^{x}}, x\in(0,\infty)$ <div class="separator" style="clear: both; text-align: center;"><img border="0" src="http://4.bp.blogspot.com/-nhTRxbTWRJc/VB2CFmXvXMI/AAAAAAAAB9U/N4BF7Czik5U/s1600/Screenshot%2Bfrom%2B2014-09-20%2B21%3A31%3A10.png" /></div>\begin{equation}\nonumber \begin{aligned} \displaystyle\lim_{x\to-\infty}F(x)&amp;=\displaystyle \lim_{x\to 0}F(x)=1-\displaystyle\lim_{x\to 0} \left(\frac{1}{e^{x}}\right) =0\\[0.5cm] \displaystyle\lim_{x\to\infty}F(x)&amp;=1- \displaystyle\lim_{x\to\infty} \left(\frac{1}{e^{x}}\right)=1 \end{aligned} \end{equation} </li><li>\begin{equation}\nonumber \frac{dF(x)}{dx}=\frac{d}{dx}\left(1-\frac{1}{e^{x}}\right)=0-(-e^{-x})=\frac{1}{e^{x}} \end{equation} $F(x)$ is an increasing function since $\frac{1}{e^{x}}&gt;0,\;\forall\;x\in(0,\infty)$. </li><li>$F(x)$ is right-continuous, since it is continuous.</li></ol>$\hspace{12.5cm}\blacksquare$ </li><li><i>Proof</i>. The function in Equation (1.5.6) is given by, \begin{equation} F_Y(y)=\begin{cases} \displaystyle\frac{1-\varepsilon}{1+e^{-y}}&\text{if}\;y<0,\; \text{for some}\;\varepsilon, 1>\varepsilon>0\\ \varepsilon+\displaystyle\frac{1-\varepsilon}{1+e^{-y}}&\text{if}\;y\geq 0,\;\text{for some}\;\varepsilon, 1>\varepsilon>0 \end{cases}\nonumber \end{equation} <img border="0" src="http://1.bp.blogspot.com/-0OsDJFLLU2g/VB2GiGALF6I/AAAAAAAAB9c/2ypXBlpWPlM/s1600/Screenshot%2Bfrom%2B2014-09-20%2B21%3A51%3A06.png" /><ol type="i"><li>\begin{equation}\nonumber \begin{aligned} \displaystyle\lim_{y\to-\infty}F_Y(y)&amp;=\displaystyle\lim_{y\to-\infty} \left(\displaystyle\frac{1-\varepsilon}{1+e^{-y}}\right)=\displaystyle\lim_{y\to-\infty} \left(\displaystyle\frac{1-\varepsilon}{1+\frac{1}{e^{y}}}\right)=0\\[0.5cm] \displaystyle\lim_{y\to\infty}F(y)&amp;=\displaystyle\lim_{y\to\infty} \left(\varepsilon+\displaystyle\frac{1-\varepsilon}{1+e^{-y}}\right)=\varepsilon + \displaystyle\lim_{y\to\infty} \left(\displaystyle\frac{1-\varepsilon}{1+\frac{1}{e^{y}}}\right)=1 \end{aligned} \end{equation} </li><li>For $y<0$, we have \begin{equation} \begin{aligned} \frac{d}{dy}\left(\frac{1-\varepsilon}{1+e^{-y}}\right)&=(1-\varepsilon)\frac{d}{dy}\left(\frac{1}{1+e^{-y}}\right)\\ &=(1-\varepsilon)\frac{(1+\varepsilon^{-y})\cdot 0 - 1\cdot e^{-y}(-1)}{(1+e^{-y})^2}\\ &=\frac{(1-\varepsilon)e^{-y}}{(1+e^{-y})^2} \end{aligned}\nonumber \end{equation} $(1-\varepsilon)>0$ since $0<\varepsilon<1$. Thus for all $y < 0$, $\frac{(1-\varepsilon)e^{-y}}{(1+e^{-y})^2}>0$, implying that the function is increasing. <br /><br />For $y\geq 0$,  \begin{equation} \begin{aligned} \frac{d}{dy}\left(\varepsilon+\frac{1-\varepsilon}{1+e^{-y}}\right)&=\varepsilon+\frac{(1-\varepsilon)e^{-y}}{(1+e^{-y})^2} \end{aligned}\nonumber \end{equation} The function is increasing since $\varepsilon + \frac{(1-\varepsilon)e^{-y}}{(1+e^{-y})^2}>0$ for all $y\geq 0$.</li><li>Since the function is continuous, then the function is right-continuous.</li></ol>$\hspace{12.5cm}\blacksquare$ </li></ol></li><li><i>Proof</i>. We know that, \begin{equation}\nonumber P(X&gt;t)=1-P(X\leq t)=1-F_X(t) \end{equation} and \begin{equation}\nonumber P(Y&gt;t)=1-P(Y\leq t)=1-F_Y(t) \end{equation} Hence we have, \begin{equation}\nonumber \begin{aligned} P(X&gt;t)=1-F_X(t)\;&amp;\overset{?}{\geq}\;1-F_Y(t)=P(Y&gt;t)\\ \end{aligned} \end{equation} Since $F_X(t)\leq F_Y(t)$, then the difference $1-F_X(t)$ tends to get bigger than $1-F_Y(t)$. Thus for all $t$, $P(X&gt;t)\geq P(X&gt;t)$.<br /><br />Now if $F_X(t) &lt; F_Y(t)$ for some $t$, then using the same argument above, $P(X&gt;t) > P(X&gt;t)$ for some $t$. <br />$\hspace{13.5cm}\blacksquare$</li><li><i>Proof</i>. For a function to be a pdf, it has to satisfy the following: <ol type="a"><li>$g(x)\geq 0$ for all $x$; and,</li><li> $\displaystyle\int_{-\infty}^{\infty}g(x)\,dx=1$.</li></ol>For any arbitrary $x_0$, $F(x_0)<1$. Thus, $g(x)$ is always positive. Now, \begin{equation} \begin{aligned} \int_{-\infty}^{\infty}g(x)\,dx&= \int_{-\infty}^{x_0}g(x)\,dx+ \int_{x_0}^{\infty}g(x)\,dx\\ &=\int_{x_0}^{\infty}g(x)\,dx\\ &=\int_{x_0}^{\infty}\frac{f(x)}{(1-F(x_0))}\,dx\\ &=\frac{1}{1-F(x_0)}\int_{x_0}^{\infty}f(x)\,dx\\ &=\frac{1}{1-F(x_0)}[F(\infty)-F(x_0)]\\ &=\frac{1}{1-F(x_0)}[1-F(x_0)]=1,\;\text{since}\;\lim_{x\to \infty}F(x)=1\\ \end{aligned}\nonumber \end{equation} $\hspace{13.5cm}\blacksquare$</li><li>In order for $f(x)$ to be a pdf, it has to integrate to 1. <ol type="a"><li>\begin{equation} \begin{aligned} \int_{-\infty}^{\infty}f(x)&amp;=\int_{0}^{\frac{\pi}{2}}\mathrm{c}\sin x=\displaystyle\left.-(\mathrm{c})\cos x\displaystyle\right\rvert_{0}^{\frac{\pi}{2}}\\ &amp;=-\mathrm{c}\left(\cos\left(\frac{\pi}{2}\right)-\cos(0)\right)\\ &amp;=-\mathrm{c}(0-1)=1\mathrm{c} \end{aligned}\nonumber \end{equation} Hence, $\mathrm{c}$ is 1. Confirm this with python,<br/><br/><script src="https://gist.github.com/alstat/5c547c22bb8584743aed.js"></script></li><li>\begin{equation} \begin{aligned} \int_{-\infty}^{\infty}f(x)&amp;=\int_{-\infty}^{\infty} \mathrm{c}\,e^{-|x|}\\ &amp;=\mathrm{c}\left(\int_{-\infty}^{0} \,e^{x}\,dx+\int_{0}^{\infty} e^{-x}\,dx\right)\\ &amp;=\mathrm{c}\left[(e^{0}-e^{-\infty})-(e^{-\infty}-e^{0})\right]\\ &amp;=\mathrm{c}(1+1) = 2\mathrm{c} \end{aligned}\nonumber \end{equation} Hence, c is $\frac{1}{2}$. Confirm this with Python,<br/><br/><script src="https://gist.github.com/alstat/8f69c125655ec96dedd5.js"></script><br/><img border="0" src="http://4.bp.blogspot.com/-Xe4JlEgE5yU/VB2UYcYw6QI/AAAAAAAAB9o/lVzwbVHQQO0/s1600/Screenshot%2Bfrom%2B2014-09-20%2B22%3A48%3A04.png" /></li></ol></li></ol></div><h3>Reference</h3><ol><li><a href="http://www.amazon.com/Statistical-Inference-George-Casella/dp/0534243126" target="_blank">Casella, G. and Berger, R.L. (2001). <i>Statistical Inference</i>. Thomson Learning, Inc.</a>  </li></ol></div><div class="author">
  <img src="" style="width: 96px; height: 96;">
  <span style="position: absolute; padding: 32px 15px;">
    <i>Original post by <a href="http://twitter.com/">Alstatr</a> - check out <a href="http://alstatr.blogspot.com/">Analysis with Programming</a></i>
  </span>
</div>
